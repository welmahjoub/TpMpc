source("./fonctions_tp_reg.R")

# Chargement des donnÃ©es : 
ozone = read.table("./ozone.txt", header = T)
# Nous allons travailler durant tout ce TP avec ces donnÃ©es.

# Les individus de ce tableau de donnÃ©es reprÃ©sentent des jours.
# Pour chacun de ces jours, on a relevÃ© plusieurs mesures mÃ©tÃ©orologiques : 
# - y : la valeur maximale de la concentration en ozone (O3) dans la journÃ©e
# - x1, x2, et x3 : les tempÃ©ratures Ã  9h, 12h, et 15h
# - x4, x5, et x6 : la nÃ©bulositÃ© Ã  9h, 12h, et 15h
# - x7, x8, et x9 : projection du vent sur l'axe EO Ã  9h, 12h et 15h
# - x10 : la concentration maximale en ozone de la veille

# L'objectif de ce TP est de mettre en oeuvre les techniques vues
# en cours afin de trouver le meilleur modÃ¨le pour prÃ©dire y en utilisant x1, x2, ... , x10.

# Je vous donne Ã©galement 10 individus nouveaux (dans le fichier ozone_n).
# Notre objectif est de faire des prÃ©dictions pour ces individus, et les meilleurs possibles !
# Dans ce fichier ozone_n, il y a Ã©galement la vÃ©ritÃ© (ce qu'on souhaite prÃ©dire). Normalement,
# nous ne sommes pas censÃ©s connaÃ®tre cette vÃ©ritÃ©. Mais pour illustrer les diffÃ©rentes notions
# de ce TP, on va faire comme si on connaissait la vÃ©ritÃ©. (ce qui n'arrivera jamais en pratique !)
# Pour charger ces 10 nouveaux individus : 
ozone_n = read.table("./ozone_n.txt", header = T)




# Question : Combien y a t'il de lignes et de colonnes dans le 
dim(ozone)
[1] 101  11
#nbre de ligne 101 et nb colonne 11
# tableau ozone ? Et dans le tableau ozone_n ?
dim(ozone_n)
#nbre de ligne 10 et nbre de colonne 11
# Afficher le dÃ©but de chacun de ces tableaux (commande head())
 head(ozone)
head(ozone_n)

######## Exercice 1 : PrÃ©diction de y Ã  partir d'une seule variable
# Dans cet exercice, nous supposons que nous n'avons le droit d'utiliser
# qu'une seule variable (parmi les x_i) pour prÃ©dire y. L'objectif est de 
# dÃ©terminer laquelle semble la plus adaptÃ©e.

# On va commencer par crÃ©er un modÃ¨le pour prÃ©dire y en fonction de x1.
# La regression linÃ©aire avec R se fait grÃ¢ce Ã  la commande lm()
# Elle s'utilise de la faÃ§on suivante :
mod = lm(y~x1, data = ozone)
# Cela signifie qu'un modÃ¨le de regrÃ©ssion de y en fonction de x1 
# dans le tableau de donnÃ©es ozone est crÃ©Ã©. IL faut Ã©videmment
# qu'existent de telles colonnes dans ozone

# Vous pouvez Ã©galement utiliser la fonction myreg() du fichier fonctions_tp_reg.R
# Elle sera plus pratique d'utilisation pour les exercices d'un peu plus tard, 
# mais autant l'utiliser tout de suite
# Aller voir dans le fichier pour comprendre sa description et comment l'utiliser.
mod1 = myreg(ozone, 2,1) # cela crÃ©Ã© le mÃªme modÃ¨le que celui avec la commande lm ci dessus

# Affichage des donnÃ©es et de la droite de rÃ©gression :
plot(ozone$x1, ozone$y)
abline(mod1, col = "red")

# Vous avez accÃ¨s Ã  diffÃ©rentes informations sur le modÃ¨le de regrÃ©ssion : 
summary(mod1)
(Intercept) -33.0106 
x1            6.7460
 mod$coefficients

# Question : repÃ©rez grÃ¢ce Ã  cette commande les informations suivantes sur le modÃ¨le que l'on vient de crÃ©er
# - les coefficients du modÃ¨le (accÃ¨s direct via mod$coefficients). Quelle est l'Ã©quation du modÃ¨le ?

#equation y=-33.0106 +6.7460x1

# - mod$residuals vous donne les valeurs des rÃ©sidus pour chaque individu qui a servi Ã  crÃ©er le modÃ¨le. En dÃ©duire le SCE_r
mod$residuals

sce_r = sum(mod$residuals^2)
sce_r 
39455.8
# - le coefficient de dÃ©termination (summary(mod)$r.squared)
summary(mod)$r.squared
#R^2=0.5159751
# - la valeur test du test de Fisher (summary(mod)$fstatistic). Comparer cette valeur avec le quantile de Fisher qf(...)
# et en dÃ©duire que le modÃ¨le complet est statistiquement significatif


summary(mod)$fstatistic
  value    numdf    dendf 
105.5349   1.0000  99.0000 

#quantil de fisher avec .95%, nbre de variable p= 1,  et n-p-1=99

qf(.95,1,99)
 3.937117

on a :
105.5349 >>>  3.937117 on rejette H0 =>> x est influe significativement

# Le coeff de dÃ©termination et le SCE_r  sont des critÃ¨res qui permettent de
# comparer la performance de diffÃ©rents modÃ¨les de prÃ©diction (avec le mÃªme
# nombre de variables uniquement). Gardez en mÃ©moire les valeurs de ces critÃ¨res pour ce premier modÃ¨le.

# Question : 
# Essayer maintenant de crÃ©er un modÃ¨le (qu'on appellera mod4) pour prÃ©dire y en fonction de x4.
# Regardez les valeurs des 2 critÃ¨res de performance pour ce modÃ¨le.
# x4 semble t'elle plus adaptÃ©e que x1 pour prÃ©dire y ?
res=sapply(c(2:11),function(x){
mod1 = myreg(ozone, x,1);

 summary(mod1)$r.squared;#r2
 
 
})
res
> res des R au carré
 [1] 0.5159751 0.6128946 0.5973574 0.3781787 0.3969218 0.2256940 0.2600824
 [8] 0.1862145 0.1443667 0.4697289




res=sapply(c(2:11),function(x){
mod1 = myreg(ozone, x,1);

 ssum(mod1$residuals^2);#scer

})

res


#> res des scer
 #[1] 39455.80 31555.31 32821.84 50688.42 49160.56 63118.37 60315.17
 #[8] 66336.59 69747.85 43225.61

R^2X4= 0.3781787 <<< R^2X1

X1 est plus adapté que x4

res# le plus petit r2  est x9

x2 est plus adapté car comporte le plus grand R2

# Essayez une par une les autres variables prÃ©dictrices (x2, x3, etc...) et conclure
# quant Ã  la variable la plus adaptÃ©e pour prÃ©dire y.
# Les 2 critÃ¨res (coefficient de dÃ©termination et SCE_R) sont-ils en accord ?
# Aide : commande sapply() permet de faire Ã§a vite.

# CrÃ©er un modÃ¨le mod_best qui correspond au meilleur modÃ¨le que vous venez de trouver.


mod4= myreg(ozone, 5,1);

mod_best= myreg(ozone, 3,1);


# On va maintenant utiliser le jeu de donnÃ©es ozone_n pour vÃ©rifier comment se comportent les diffÃ©rents modÃ¨les
# que l'on vient de crÃ©er pour prÃ©dire des nouvelles donnÃ©es.
# La commande

prediction=predict(mod4, ozone_n)

#   1         2         3         4         5 
 90.66269  97.35211  77.28385  77.28385 110.73096 
        6         7         8         9        10 
 77.28385  77.28385 104.04153 124.10980  90.66269 

mod4= myreg(ozone, 5,1);
eq=prediction-ozone_n$y
eqm=mean(eq^2)
eqm# 343.2581

# calculer eqm des 3 modele(1,2et4)

sapply(c(2,3,5),function(x){
 mod = myreg(ozone, x,1);

 prediction=predict(mod, ozone_n)
 eq=prediction-ozone_n$y
 mean(eq^2)

})

# 304.8180 216.8478 343.2581

# c est le model (2) qui le plus petit eqm 
# classement eqm : 2 , 1 puis 4
#classement r2 et scer: 2,1 puis 4

# donc meme classement

# prÃ©dit (en utilisant le modÃ¨le mod) la variable y (car c'est la variable cible du modÃ¨le mod) des individus de ozone_n

# Question : 
# Pour les 3 modÃ¨les que l'on vient de crÃ©er (mod1, mod4, et mod_best), calculer l'EQM du modÃ¨le sur les donnÃ©es de ozone_n
# Autrement dit, utiliser chaque modÃ¨le pour prÃ©dire, puis comparer les prÃ©dictions Ã  la vÃ©ritÃ©.

# En termes de performance, comment sont classÃ©s ces 3 modÃ¨les (du meilleur au moins bon) d'aprÃ¨s les EQM que vous venez de calculer ?
# Si vous n'avez pas fait d'erreurs, les critÃ¨res (coefficient de dÃ©termination et SCE_R) sont en accord avec ce classement des modÃ¨les.
# Tant mieux, cela semble vouloir dire que ces critÃ¨res peuvent permettre de trouver quel modÃ¨le semble Ãªtre le plus performant (
# normalement on ne peut pas se baser sur l'EQM du nouveau jeu de donnÃ©es ozone_n car on n'est pas censÃ© le connaÃ®tre)

######### Exercice 1-bis : Comparaison avec un modÃ¨le Ã  2 variables prÃ©dictrices

# CrÃ©er un modÃ¨le qu'on appelle mod_2variables (avec lm ou myreg) pour prÃ©dire y en fonction de x2 (la meilleure variable seule) et x1.

 mod_2variables= myreg(ozone, c(2,3),1);
 summary( mod_2variables)$r.squared;#r2 :  0.6154227
 sum( mod_2variables$residuals^2);#scer  : 31349.22

# Calculer les 2 critÃ¨res de performance (coeff de determination et SCE_r) de ce nouveau modÃ¨le.

# Selon ces critÃ¨res, ce modÃ¨le est-il meilleur que les 3 modÃ¨les prÃ©cÃ©dants ?

# oui le r2 est augmenter car on a mis plus de variable 
# scer est plus petit que tous les modele 

# Utiliser ce modÃ¨le pour prÃ©dire y des individus de ozone_n, et calculer l'EQM sur ces donnÃ©es.
# Vous devriez voir que les 2 critÃ¨res ne sont pas en accord avec cette EQM. 

 prediction=predict( mod_2variables, ozone_n)
 eq=prediction-ozone_n$y
 mean(eq^2)# 225.946

# eqm du modele avec 2 variable et plus grand que le eqm du modele avec la variable x2

# C'est assez embÃªtant car si l'on suit ces critÃ¨res on va utilser le modÃ¨le Ã  2 variables, alors qu'a priori il sera 
# moins bon pour prÃ©dire des nouvelles donnÃ©es. 

# La raison est (comme je vous l'ai montrÃ© en cours) que ces critÃ¨res favorisent toujours des modÃ¨les avec un plus grand
# nombre de variables. MÃªme si on ajoute des variables complÃ©tement alÃ©atoires par rapport Ã  y, les critÃ¨res diront que 
# ces variables permettent d'amÃ©liorer le modÃ¨le (alors que c'est aberrant).

# Il ne faut donc surtout pas utiliser ces critÃ¨res pour comparer des modÃ¨les qui n'ont pas le mÃªme nombre de variables.

# Un critÃ¨re plus fiable et qui peut Ãªtre utilisÃ© quelque soit le nombre de variables est l'erreur de gÃ©nÃ©ralisation d'un modÃ¨le (cf cours)
# Mais il fait Ãªtre capable de bien l'estimer, c'est l'objet de l'exercice 2.



######## Exercice 2 : Estimation de l'erreur de gÃ©nÃ©ralisation d'un modÃ¨le par
#### sÃ©paration apprentissage / test.

# Nous avons vu en cours que l'erreur de gÃ©nÃ©ralisation Ã©tait un critÃ¨re plus appropriÃ©
# pour comparer les performances de diffÃ©rents modÃ¨les de prÃ©diction (notemment avec 
# un nombre de variables diffÃ©rents). Pour estimer l'erreur de gÃ©nÃ©ralisation
# d'un modÃ¨le, il faut nÃ©anmois procÃ©der correctement. La sÃ©paration apprentissage/test

# fait partie des techniques qui permettent d'estimer avec fiabilitÃ© cette erreur
# de gÃ©nÃ©ralisation. Vous allez la mettre en place dans cet exercice afin de sÃ©lectionner
# le meilleur modÃ¨le Ã  1 variable suivant le critÃ¨re de l'erreur de gÃ©nÃ©ralisation.
# Rappel de la procÃ©dure d'estimation de l'erreur de gÃ©nÃ©ralisation par
# sÃ©paration apprentissage/test : 
# 1) Choisir alÃ©atoirement 70% (ou 75%) des individus et les mettre dans un ensemble d'apprentissage
# 2) Mettre les individus restants dans un ensemble de test
# 3) Apprendre un modÃ¨le de rÃ©gression (y en fonction de x1 par ex) en utilisant uniquement les individus de l'ensemble 
# d'apprentissage

# 4) PrÃ©dire Ã  l'aide de ce modÃ¨le la variable y pour tous les individus de l'ensemble de
# test, et calculer l'EQM de ces prÃ©dictions. Cette EQM reprÃ©sente l'estimation de
# l'erreur de gÃ©nÃ©ralisation du modÃ¨le.

# A vous de jouer, Ã©tape par Ã©tape : 

# Etapes 1 et 2: CrÃ©er un ensemble d'apprentissage contenant 70% (alÃ©atoirement) des individus d'ozone
# et un ensemble de test contenant les 30% restants
# Aide : 
# Il y a 101 individus dans ozone, 70% reprÃ©sente donc 70 individus
# La commande sample(101,70) tire au hasard 70 valeurs entre 1 et 101. Ces valeurs
# peuvent vous servir pour reprÃ©senter les indices des lignes d'ozone que vous
# voulez mettre dans l'ensemble d'apprentissage. 
# Rappel : si vous voulez garder les lignes 4, 12, et 20 d'un tableau tab, vous 
# pouvez procÃ©der comme suit : 

ap_index=sample(101,70)
apprenti=ozone[ap_index,]
test=ozone[-ap_index,]


# idx = c(4,12,20) --> idx est un vecteur contenant les indices des lignes Ã  garder

# tab[idx, ]  rÃ©cupÃ¨re les lignes de tab dont les indices sont dans idx.
# et tab[-idx, ] prend toutes les lignes de tab sauf celles dont les indices sont dans idx
# Avec Ã§a, je pense que vous pouvez crÃ©er l'ensemble d'apprentissage et de test
# facilement

# Etape 3
# Apprendre un modÃ¨le de rÃ©gression y~x1 avec l'ensemble d'apprentissage.
# Facile

 mod1= myreg(apprenti, 2,1);

# Etape 4 : Utiliser ce modÃ¨le pour prÃ©dire les valeurs de y des individus de 
# l'ensemble de test. Facile avec la commande predict.

 prediction=predict( mod1,test )

# Calculer l'EQM de ces prÃ©dictions.

 eq=prediction-test$y

 mean(eq^2)#  293.2935

# Quelle est l'estimation de l'erreur de gÃ©nÃ©ralisation du modÃ¨le qui prÃ©dit y 
# Ã  partir de x1 ?
 293.2935

# Afin d'automatiser cette procÃ©dure, je vous conseille de crÃ©er une fonction :
# separation = function(data, idxp, idxc){...}

# qui renvoie une estimation de l'erreur de gÃ©nÃ©ralisation d'un modÃ¨le de regrÃ©ssion 
# pour prÃ©dire la colonne d'indice idxc de data Ã  partir des colonnes d'indice idxp
# Il vous suffit d'utiliser myreg ainsi que les commandes que vous avez rÃ©alisÃ©es dans
# les Ã©tapes 1 Ã  4 ci-dessous et de mettre le tout dans le corps de la fonction.
# Attention Ã  bien faire cette fonction gÃ©nÃ©rique.
# La signature de la fonction est Ã©crite dans le fichier "fonctions_tp_reg.R"



# Question: Estimer l'erreur de gÃ©nÃ©ralisation des 4 modÃ¨les que l'on a dÃ©jÃ  crÃ©Ã©s : mod2, mod4, mod_best, mod_2variables
# Quel est le meilleur modÃ¨le suivant cette estimation ?

source("./fonctions_tp_reg.R")

eqm1=separation(ozone,2,1);
eqm1#333.6034

sapply(c(3,5,2,c(2,3)),function(x){

  separation(ozone,x,1);
})
# modele 2 , 4 , 1 , modele avec deux variable (1 et 2)
# 306.8703 389.6565 378.6420 586.1540 314.6059

# le plus c est le modele 2 ( best)

# Question : Estimer une deuxiÃ¨me fois ces 4 erreurs de gÃ©nÃ©ralisation (procÃ©dure
# entiÃ¨re Ã  refaire). Obtient-on les mÃªmes conclusions ? Est ce normal ?

# non on trouve pas le mme ordre

# Question : 
# Utiliser le critÃ¨re d'estimation de l'erreur de gÃ©nÃ©ralisation par sÃ©paration 
# app / test  pour choisir la meilleure variable x1, x2, ..., x10 
# Ã  utiliser pour prÃ©dire y.
# Vous pouvez Ã©ventuellement crÃ©er une fonction qui prend en entrÃ©e un 
# tableau de donnÃ©es, l'indice de la variable cible et qui renvoie le 
# meilleur modÃ¨le de rÃ©gression Ã  1 variable pour prÃ©dire cette variable cible
# tout en affichant l'estimation de son erreur de gÃ©nÃ©ralisation.
# Aide : la commande sapply (que vous connaissez) peut vous faciliter la tÃ¢che

source("./fonctions_tp_reg.R")

meilleurmodele(ozone,1)

meilleurmodele_stable(ozone, c(2:11), 1,100)#2

meilleur_stable(ozone,1)#2

# Refaites une seconde fois toute la procÃ©dure qui vous permet
# de choisir la meilleure variable pour prÃ©dire y.
# Trouvez vous le mÃªme rÃ©sultat que la premiÃ¨re fois ?non


# La sÃ©paration aÃ©atoire apprentissage/test n'est pas la faÃ§on la plus
# fiable pour estimer l'erreur de gÃ©nÃ©ralisation d'un modÃ¨le.
# On va maintenant essayer d'amÃ©liorer la prÃ©cision de l'estimation de l'erreur
# de gÃ©nÃ©ralisation. 

# Une faÃ§on (facile et directe) d'amÃ©liorer cette estimation est la suivante :
# On fait plusieurs sÃ©paration app/test alÃ©atoires, et on moyenne
# les rÃ©sultats obtenus pour chaque sÃ©paration.

# Question : 
# Modifiez votre fonction separation de faÃ§on Ã  amÃ©liorier la prÃ©cision de l'estimation
# Aide : il suffit de faire une boucle for qui fait plusieurs fois ce que vous venez
# de faire, et faire une moyenne Ã  la fin.

# Appliquer maintenant cette mÃ©thode d'estimation de l'erreur de gÃ©nÃ©ralisation pour choisir
# la meilleure variable (x1 Ã  x10) pour prÃ©dire y. 

# Le rÃ©sultat est-il plus stable ?

# La mÃ©thode la plus fiable (et plus jolie) pour estimer l'erreur de gÃ©nÃ©ralisation 
# est la validation croisÃ©e Ã  K plis prÃ©sentÃ©e en cours. 
# Elle est un peu plus compliquÃ©e Ã  mettre en place. 
# Nous y reviendrons un peu plus tard.


pour nous l'eqm qui renvoie 2 est pour la var x2 


